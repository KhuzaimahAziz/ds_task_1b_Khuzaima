{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+H+nCOIvXxFurQ9sSaQfJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhuzaimahAziz/ds_task_1b_Khuzaima/blob/main/ds_task_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilMRYh3zQp2s",
        "outputId": "a04c3a50-96e5-47c4-f2fa-e3eb7e54e707"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.2-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 KB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.2 yarl-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Giuq_KEcLxlX"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "def recommendations(q1, q2, q3, q4):\n",
        "    prompt = f\"\"\"\n",
        "    Given the following information, recommend a list of fruits:\n",
        "    \n",
        "    Q1: Do you go out to party on weekends?{q1}\n",
        "    Q2: What flavours do you like?(cider, sweet, waterlike){q2}\n",
        "    Q3: What texture you don't like?(smooth, slimy, rough){q3}\n",
        "    Q4: What price range will you buy drink for? ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10){q4}\n",
        "    \n",
        "    Rules:\n",
        "    If they party on weekends, apples, pears, grapes, watermelon are allowed.\n",
        "    If they like cider, show apples, oranges, lemon, lime.\n",
        "    If they like sweet, show watermelon, orange.\n",
        "    If they like waterlike, show watermelon.\n",
        "    If grapes is chosen, remove watermelon from the list.\n",
        "    If texture you don't like is smooth, remove pears.\n",
        "    If texture you don't like is slimy, remove watermelon, lime and grape.\n",
        "    If texture you don't like is waterlike, remove watermelon.\n",
        "    If price < $3 remove lime, watermelon.\n",
        "    If price > $4 and < $7 remove pears, apples.\n",
        "    Recommended fruits:\n",
        "    \"\"\"\n",
        "    \n",
        "    model = \"text-davinci-002\"\n",
        "    temperature = 0.7\n",
        "    max_tokens = 50\n",
        "    n = 1\n",
        "\n",
        "    response = openai.Completion.create(\n",
        "        engine=model,\n",
        "        prompt=prompt,\n",
        "        max_tokens=max_tokens,\n",
        "        n=n,\n",
        "        temperature=temperature,\n",
        "        stop=None,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "    )\n",
        "\n",
        "    recommended_fruits = response.choices[0].text.splitlines()\n",
        "    recommended_fruits = [fruit.strip() for fruit in recommended_fruits if fruit.strip() != \"\"]\n",
        "\n",
        "    return recommended_fruits"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Welcome to the Fruit Recommender!\")\n",
        "q1 = input(\"Do you go out to party on weekends?\")\n",
        "q2 = input(\"What flavours do you like?(cider, sweet, waterlike)\")\n",
        "q3 = input(\"What texture you don't like?(smooth, slimy, rough)\")\n",
        "q4 = input(\"What price range will you buy drink for? ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6N1TjY7mowS",
        "outputId": "213aa79d-4bf5-4494-e07c-874bd25d8858"
      },
      "execution_count": 10,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to the Fruit Recommender!\n",
            "Do you go out to party on weekends?no\n",
            "What flavours do you like?(cider, sweet, waterlike)sweet\n",
            "What texture you don't like?(smooth, slimy, rough)rough\n",
            "What price range will you buy drink for? ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recommended_fruits = recommendations(q1, q2, q3, q4)\n",
        "print(\"We recommend the following fruits:\")\n",
        "print(recommended_fruits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xy06uE-hm5qo",
        "outputId": "dc6dc056-cefa-4adc-d568-f493dc890ece"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We recommend the following fruits:\n",
            "['Apples', 'Oranges', 'Lemon', 'Grape']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, jsonify, request\n",
        "app = Flask(__name__)\n",
        "\n",
        "\n",
        "\n",
        "@app.route('/recomended_fruits')\n",
        "def get_fruits():\n",
        "    return jsonify(recommended_fruits)\n",
        "\n",
        "\n",
        "@app.route('/recommended_fruits', methods=['POST'])\n",
        "def add_fruits():\n",
        "    recommended_fruits.append(request.get_json())\n",
        "    return '', 204\n",
        "\n",
        "app.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tts6gK3GQrrd",
        "outputId": "54267550-34cd-46d8-9ac3-aa45b41ca78c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8ZHK-54YtcVX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}